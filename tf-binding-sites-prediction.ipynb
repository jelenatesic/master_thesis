{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing important libreries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for visualisation\n\nimport tensorflow as tf # for deep nn models\nimport scikitplot as skplt # for visualisation\nfrom sklearn import metrics \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-30T20:24:46.125545Z","iopub.execute_input":"2023-08-30T20:24:46.127470Z","iopub.status.idle":"2023-08-30T20:24:46.135182Z","shell.execute_reply.started":"2023-08-30T20:24:46.127411Z","shell.execute_reply":"2023-08-30T20:24:46.133179Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Making a class for data importing","metadata":{}},{"cell_type":"markdown","source":"The data has been saved in npy format, so in order to import it, we will make a new class, that will do it for us.","metadata":{}},{"cell_type":"code","source":"class read_data:\n    \"\"\"After calling this class, we will have our data loaded\"\"\"\n    \n    def __init__(self):\n        \n        train_path = '/kaggle/input/bioinformatics/machine_learning/JUND_TF/train/'\n        valid_path = '/kaggle/input/bioinformatics/machine_learning/JUND_TF/valid/'\n        test_path = '/kaggle/input/bioinformatics/machine_learning/JUND_TF/test/'\n        \n        self.train = {}; self.valid = {}; self.test = {} # making empty dictionaries \n        \n        # Importing Training dataset: witch consists of features X, wights W and labels Y       \n        with open(train_path + 'train_X.npy', 'rb') as f:\n            self.train['X'] = np.load(f) # as it is in .npy format\n        f.close()\n        \n        with open(train_path + 'train_y.npy', 'rb') as f:\n            self.train['y'] = np.load(f)\n        f.close()\n        \n        with open(train_path + 'train_w.npy', 'rb') as f:\n            self.train['w'] = np.load(f)\n        f.close()\n        \n        with open(train_path + 'train_ids.npy', 'rb') as f:\n            self.train['ids'] = np.load(f, allow_pickle=True)\n        f.close()\n        \n        \n        # All the same for the VALIDATION dataset\n        with open(valid_path + 'valid_X.npy', 'rb') as f:\n            self.valid['X'] = np.load(f)\n        f.close()\n        \n        with open(valid_path + 'valid_y.npy','rb') as f:\n            self.valid['y'] = np.load(f)\n        f.close()\n        \n        with open(valid_path + 'valid_w.npy', 'rb') as f:\n            self.valid['w'] = np.load(f)\n        f.close()\n        \n        with open(valid_path + 'valid_ids.npy', 'rb') as f:\n            self.valid['ids'] = np.load(f, allow_pickle=True)\n        f.close()\n        \n        # All the same for the TEST dataset\n        with open(test_path+'test_X.npy','rb') as f:\n            self.test['X'] = np.load(f)\n        f.close()\n        \n        with open(test_path+'test_y.npy','rb') as f:\n            self.test['y'] = np.load(f)\n        f.close()\n        \n        with open(test_path+'test_w.npy','rb') as f:\n            self.test['w'] = np.load(f)\n        f.close()\n        \n        with open(test_path+'test_ids.npy','rb') as f:\n            self.test['ids'] = np.load(f,allow_pickle=True)\n        f.close()\n        \n        # Adding chromatic accessibility fearure from accessability.txt\n        def add_chrom(self):\n            \n            span_accessibility = {}\n            for line in open ('/kaggle/input/bioinformatics/machine_learning/JUND_TF/accessibility.txt'):\n                fields = line.split() # splitting features so we get KEY and VALUE\n                span_accessibility[fields[0]] = float(fields[1])\n        \n    \n            # Finding the correct value for txt \n            def dicarray_df(case):\n\n                # Making sure that we take the right set, before sorting\n                if (case == 'train'):\n                    case_id = self.train\n                elif(case == 'valid'):\n                    case_id = self.valid\n                elif(case == 'test'):\n                    case_id = self.test\n\n                # Making temporary empty DataFrame, for sorting\n                ldf = pd.DataFrame([k,*v] for k,v in case_id.items())\n\n                ldf = ldf.T \n                ldf.columns = ['X', 'y', 'w', 'ids']\n                ldf.drop(0, axis = 0, inplace = True) # allows you to remove row (axis = 0) number 0 (1st one)\n                ldf.reset_index(drop = True, inplace = True) # removing current indexes \n\n                # Extracting chromosom\n                ldf['chrom'] = ldf['ids'].map(span_accessibility) # map puts together 'ids' with span_acceibility \n                # print(os.getcwd())\n                # os.chdir('/kaggle/working/')\n\n                # This function adds chromosom info and saves it \n                np.save(f'./chrom_{case}.npy', ldf['chrom'].values)\n            \n            # calling function\n            dicarray_df('train')\n            dicarray_df('valid')\n            dicarray_df('test')\n\n            # Match and save\n            array = np.load('./chrom_train.npy')\n            self.train['chrom'] = array\n\n            array = np.load('./chrom_valid.npy')\n            self.valid['chrom'] = array\n\n            array = np.load('./chrom_test.npy')\n            self.test['chrom'] = array","metadata":{"execution":{"iopub.status.busy":"2023-08-30T20:24:49.064205Z","iopub.execute_input":"2023-08-30T20:24:49.064620Z","iopub.status.idle":"2023-08-30T20:24:49.094850Z","shell.execute_reply.started":"2023-08-30T20:24:49.064587Z","shell.execute_reply":"2023-08-30T20:24:49.093286Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Importing data ","metadata":{}},{"cell_type":"markdown","source":"Here are presented Encoded data of DNA sequence from the chromosome 22. The data thath will be used is from the course: Deep Learning for the Life Sciences. The aim of this project is to predict Transcription Factor binding locations in ch22. The data is presented in the form of one dimensional data, where the DNA sequence of ch22, which is consisted od more than 50 milion bases, is split in sequences of length 101 bases. Those sequences are then encoded, using One Hot Encoding, where each base is presented with the vector of lenght 4. The encodings are: \nА → [1, 0, 0, 0],\nC → [0, 1, 0, 0],\nG → [0, 0, 1, 0],\nT → [0, 0, 0, 1],","metadata":{}},{"cell_type":"code","source":"data = read_data()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T20:26:13.190956Z","iopub.execute_input":"2023-08-30T20:26:13.191539Z","iopub.status.idle":"2023-08-30T20:26:15.502345Z","shell.execute_reply.started":"2023-08-30T20:26:13.191500Z","shell.execute_reply":"2023-08-30T20:26:15.501036Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# # Checking the shape of loaded data\ndata_info = {\"Features\": [\"Feature Matrix\", \"Labels\", \"Sample Weighting\"],\n             \"Train\": [data.train['X'].shape, data.train['y'].shape,data.train['w'].shape],\n            \"Validation\": [data.valid['X'].shape, data.valid['y'].shape, data.valid['w'].shape],\n            \"Test\": [data.test['X'].shape,data.test['y'].shape, data.test['w'].shape]}\ndata_info = pd.DataFrame(data_info)\n\ndata_info","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:41:04.559701Z","iopub.execute_input":"2023-08-27T19:41:04.560084Z","iopub.status.idle":"2023-08-27T19:41:04.595204Z","shell.execute_reply.started":"2023-08-27T19:41:04.560052Z","shell.execute_reply":"2023-08-27T19:41:04.593724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of positives and negatives in our dataset\nlabels = pd.DataFrame(np.concatenate([data.train['y'], data.test['y'], data.valid['y']], axis = 0), columns = ['y'])\nlabels['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-27T11:25:19.388267Z","iopub.execute_input":"2023-08-27T11:25:19.388663Z","iopub.status.idle":"2023-08-27T11:25:19.409511Z","shell.execute_reply.started":"2023-08-27T11:25:19.388633Z","shell.execute_reply":"2023-08-27T11:25:19.408586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trening_labels = pd.DataFrame(np.concatenate([data.train['y']]), columns = ['y'])\n\ntest_labels = pd.DataFrame(np.concatenate([data.test['y']]), columns = ['y'])\n\nvalid_labels = pd.DataFrame(np.concatenate([data.valid['y']]), columns = ['y'])\n\nprint(f\"Trening set:\\n {trening_labels['y'].value_counts()}\")\nprint(f\"\\nValidation set:\\n {valid_labels['y'].value_counts()}\" )\nprint(f\"\\nTest set:\\n {test_labels['y'].value_counts()}\" )\n","metadata":{"execution":{"iopub.status.busy":"2023-08-28T18:36:21.219505Z","iopub.execute_input":"2023-08-28T18:36:21.221033Z","iopub.status.idle":"2023-08-28T18:36:21.255799Z","shell.execute_reply.started":"2023-08-28T18:36:21.220961Z","shell.execute_reply":"2023-08-28T18:36:21.254619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Balancing classes","metadata":{}},{"cell_type":"markdown","source":"**FIRST WE MAKE A DATAFRAME OUT OF OUR DATA**","metadata":{}},{"cell_type":"code","source":"# Making a DataFrame from the train samples\n# for undersampling\nx = data.train[\"X\"]\ny = data.train['y']\nw = data.train['w']\n\ndf = {'X': [], 'y': [], 'w': []}\nfor i in range(x.shape[0]):\n    df['X'].append(x[i])\n    df['y'].append(y[i])\n    df['w'].append(w[i])\n\ntrain_df = pd.DataFrame(df)\ntrain_df.head\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T20:26:16.997693Z","iopub.execute_input":"2023-08-30T20:26:16.998197Z","iopub.status.idle":"2023-08-30T20:26:18.131053Z","shell.execute_reply.started":"2023-08-30T20:26:16.998157Z","shell.execute_reply":"2023-08-30T20:26:18.129467Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of                                                         X    y  \\\n0       [[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [1,...  [0]   \n1       [[1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...  [0]   \n2       [[0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  [0]   \n3       [[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...  [0]   \n4       [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [0,...  [0]   \n...                                                   ...  ...   \n276211  [[0, 0, 1, 0], [0, 1, 0, 0], [0, 1, 0, 0], [1,...  [0]   \n276212  [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0,...  [0]   \n276213  [[0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0,...  [0]   \n276214  [[0, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0], [0,...  [0]   \n276215  [[0, 0, 1, 0], [0, 1, 0, 0], [0, 1, 0, 0], [0,...  [0]   \n\n                           w  \n0       [0.5021232657572496]  \n1       [0.5021232657572496]  \n2       [0.5021232657572496]  \n3       [0.5021232657572496]  \n4       [0.5021232657572496]  \n...                      ...  \n276211  [0.5021232657572496]  \n276212  [0.5021232657572496]  \n276213  [0.5021232657572496]  \n276214  [0.5021232657572496]  \n276215  [0.5021232657572496]  \n\n[276216 rows x 3 columns]>"},"metadata":{}}]},{"cell_type":"markdown","source":"**DOWNSAMPLING DATA**\nTAKING 50 TIMES MORE NEGATIVES THAN POSITIVES","metadata":{}},{"cell_type":"code","source":"# DOWNSAMPLING\n\ntrain_positives = train_df[train_df['y'] == 1]\ntrain_negatives = train_df[train_df['y'] == 0]\n\n# We need to sample part of the negative ones, since there are too many negative samples\nnp.random.seed(1234) # MAKING SURE OUR SAMPLED DATA IS ALWAYS THE SAME\ntrain_negatives_downsampled = train_negatives.sample( n = train_positives.shape[0]*50)\n\ndata_train_downsampled = pd.concat([train_positives, train_negatives_downsampled])\n\ndata_train_downsampled.shape, data_train_downsampled.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T20:26:21.678879Z","iopub.execute_input":"2023-08-30T20:26:21.680229Z","iopub.status.idle":"2023-08-30T20:26:23.256553Z","shell.execute_reply.started":"2023-08-30T20:26:21.680180Z","shell.execute_reply":"2023-08-30T20:26:23.255006Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((59568, 3),\n                                                       X    y  \\\n 718   [[0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [0,...  [1]   \n 809   [[0, 0, 1, 0], [0, 1, 0, 0], [0, 1, 0, 0], [0,...  [1]   \n 997   [[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [1,...  [1]   \n 1261  [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [0,...  [1]   \n 1393  [[1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [1,...  [1]   \n \n                         w  \n 718   [118.2431506849315]  \n 809   [118.2431506849315]  \n 997   [118.2431506849315]  \n 1261  [118.2431506849315]  \n 1393  [118.2431506849315]  )"},"metadata":{}}]},{"cell_type":"code","source":"print(\"downsampled negatives> \",data_train_downsampled[data_train_downsampled['y'] == 0].shape[0])\nprint(\"positives> \", data_train_downsampled[data_train_downsampled['y'] == 1].shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T09:02:46.933842Z","iopub.execute_input":"2023-08-30T09:02:46.934329Z","iopub.status.idle":"2023-08-30T09:02:47.289827Z","shell.execute_reply.started":"2023-08-30T09:02:46.934294Z","shell.execute_reply":"2023-08-30T09:02:47.288607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TAKING OUR DATA INTO IT'S FIRST SHAPE**","metadata":{}},{"cell_type":"code","source":"X_train = np.concatenate(np.array(data_train_downsampled['X'])).reshape(data_train_downsampled['X'].shape[0],101,4)\nprint(\"Shape of the features: \",X_train.shape)\n\ny_train = np.concatenate(np.array(data_train_downsampled['y'])).reshape(data_train_downsampled['y'].shape[0],1)\nprint(\"Shape of lables\", y_train.shape)\n\nw_train = np.concatenate(np.array(data_train_downsampled['w'])).reshape(data_train_downsampled['w'].shape[0],1)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T20:26:26.254044Z","iopub.execute_input":"2023-08-30T20:26:26.254467Z","iopub.status.idle":"2023-08-30T20:26:26.671767Z","shell.execute_reply.started":"2023-08-30T20:26:26.254435Z","shell.execute_reply":"2023-08-30T20:26:26.670034Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Shape of the features:  (59568, 101, 4)\nShape of lables (59568, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Defining important features","metadata":{}},{"cell_type":"code","source":"METRICS = [\n#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n#       tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.AUC(name='auc')]\n\nBATCH_SIZE = 512\n\n# Input_Shape = data.train['X'].shape[1:]\nInput_Shape = X_train.shape[1:]","metadata":{"execution":{"iopub.status.busy":"2023-08-30T20:26:29.702444Z","iopub.execute_input":"2023-08-30T20:26:29.702882Z","iopub.status.idle":"2023-08-30T20:26:30.297331Z","shell.execute_reply.started":"2023-08-30T20:26:29.702849Z","shell.execute_reply":"2023-08-30T20:26:30.295843Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# MAKING MODELS","metadata":{}},{"cell_type":"markdown","source":"# 1D CNN= book","metadata":{}},{"cell_type":"code","source":"model_book = tf.keras.models.Sequential([\n    tf.keras.layers.Conv1D(filters = 90, \n                           kernel_size = 10,\n                          activation = 'relu',\n                          padding = 'same',\n                          input_shape = Input_Shape),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Conv1D(filters = 90, \n                           kernel_size = 10,\n                          activation = 'relu',\n                          padding = 'same'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Conv1D(filters = 90, \n                           kernel_size = 10,\n                          activation = 'relu',\n                          padding = 'same'),\n        tf.keras.layers.Dropout(0.5),\n    \n        tf.keras.layers.Flatten(),\n#         tf.keras.layers.Dense(64, activation = 'relu'),\n        tf.keras.layers.Dense(1, activation = 'sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T21:36:35.228240Z","iopub.execute_input":"2023-08-30T21:36:35.228750Z","iopub.status.idle":"2023-08-30T21:36:35.332235Z","shell.execute_reply.started":"2023-08-30T21:36:35.228714Z","shell.execute_reply":"2023-08-30T21:36:35.331038Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_book.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n               loss = 'binary_crossentropy',\n               metrics = METRICS)\n\nmodel_book.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T21:36:38.914103Z","iopub.execute_input":"2023-08-30T21:36:38.915005Z","iopub.status.idle":"2023-08-30T21:36:38.959189Z","shell.execute_reply.started":"2023-08-30T21:36:38.914953Z","shell.execute_reply":"2023-08-30T21:36:38.958064Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv1d_3 (Conv1D)           (None, 101, 90)           3690      \n                                                                 \n dropout_3 (Dropout)         (None, 101, 90)           0         \n                                                                 \n conv1d_4 (Conv1D)           (None, 101, 90)           81090     \n                                                                 \n dropout_4 (Dropout)         (None, 101, 90)           0         \n                                                                 \n conv1d_5 (Conv1D)           (None, 101, 90)           81090     \n                                                                 \n dropout_5 (Dropout)         (None, 101, 90)           0         \n                                                                 \n flatten_1 (Flatten)         (None, 9090)              0         \n                                                                 \n dense_1 (Dense)             (None, 1)                 9091      \n                                                                 \n=================================================================\nTotal params: 174,961\nTrainable params: 174,961\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(123)\nmodel_book.fit(X_train, y_train,\n            validation_data=(data.valid['X'], data.valid['y']),\n               sample_weight = w_train,\n            epochs = 50, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T21:36:42.378106Z","iopub.execute_input":"2023-08-30T21:36:42.378492Z","iopub.status.idle":"2023-08-30T23:11:18.603168Z","shell.execute_reply.started":"2023-08-30T21:36:42.378462Z","shell.execute_reply":"2023-08-30T23:11:18.601839Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/50\n117/117 [==============================] - 109s 924ms/step - loss: 1.3423 - auc: 0.6550 - val_loss: 1.4823 - val_auc: 0.5761\nEpoch 2/50\n117/117 [==============================] - 108s 925ms/step - loss: 1.3045 - auc: 0.5398 - val_loss: 1.0546 - val_auc: 0.6176\nEpoch 3/50\n117/117 [==============================] - 108s 925ms/step - loss: 1.3058 - auc: 0.5584 - val_loss: 1.3488 - val_auc: 0.6595\nEpoch 4/50\n117/117 [==============================] - 109s 929ms/step - loss: 1.2728 - auc: 0.6093 - val_loss: 1.3571 - val_auc: 0.6707\nEpoch 5/50\n117/117 [==============================] - 110s 944ms/step - loss: 1.2353 - auc: 0.6674 - val_loss: 1.2034 - val_auc: 0.6985\nEpoch 6/50\n117/117 [==============================] - 118s 1s/step - loss: 1.1950 - auc: 0.7065 - val_loss: 1.1674 - val_auc: 0.7156\nEpoch 7/50\n117/117 [==============================] - 110s 941ms/step - loss: 1.1637 - auc: 0.7289 - val_loss: 1.0281 - val_auc: 0.7423\nEpoch 8/50\n117/117 [==============================] - 111s 946ms/step - loss: 1.1330 - auc: 0.7559 - val_loss: 0.9050 - val_auc: 0.7421\nEpoch 9/50\n117/117 [==============================] - 118s 1s/step - loss: 1.1182 - auc: 0.7629 - val_loss: 0.9162 - val_auc: 0.7229\nEpoch 10/50\n117/117 [==============================] - 109s 936ms/step - loss: 1.0915 - auc: 0.7815 - val_loss: 1.0310 - val_auc: 0.7325\nEpoch 11/50\n117/117 [==============================] - 110s 937ms/step - loss: 1.0778 - auc: 0.7878 - val_loss: 0.8267 - val_auc: 0.7317\nEpoch 12/50\n117/117 [==============================] - 109s 934ms/step - loss: 1.0662 - auc: 0.7950 - val_loss: 0.7274 - val_auc: 0.7371\nEpoch 13/50\n117/117 [==============================] - 110s 938ms/step - loss: 1.0354 - auc: 0.8117 - val_loss: 0.5864 - val_auc: 0.7242\nEpoch 14/50\n117/117 [==============================] - 109s 932ms/step - loss: 1.0241 - auc: 0.8165 - val_loss: 0.7768 - val_auc: 0.7474\nEpoch 15/50\n117/117 [==============================] - 109s 931ms/step - loss: 0.9915 - auc: 0.8316 - val_loss: 0.6546 - val_auc: 0.7327\nEpoch 16/50\n117/117 [==============================] - 118s 1s/step - loss: 0.9720 - auc: 0.8384 - val_loss: 0.5421 - val_auc: 0.7357\nEpoch 17/50\n117/117 [==============================] - 109s 934ms/step - loss: 0.9572 - auc: 0.8450 - val_loss: 0.6083 - val_auc: 0.7403\nEpoch 18/50\n117/117 [==============================] - 117s 1s/step - loss: 0.9094 - auc: 0.8644 - val_loss: 0.6228 - val_auc: 0.7434\nEpoch 19/50\n117/117 [==============================] - 109s 934ms/step - loss: 0.9229 - auc: 0.8553 - val_loss: 0.4257 - val_auc: 0.7284\nEpoch 20/50\n117/117 [==============================] - 107s 920ms/step - loss: 0.8771 - auc: 0.8748 - val_loss: 0.4401 - val_auc: 0.7294\nEpoch 21/50\n117/117 [==============================] - 116s 996ms/step - loss: 0.8878 - auc: 0.8688 - val_loss: 0.5580 - val_auc: 0.7361\nEpoch 22/50\n117/117 [==============================] - 117s 1s/step - loss: 0.8444 - auc: 0.8845 - val_loss: 0.4979 - val_auc: 0.7220\nEpoch 23/50\n117/117 [==============================] - 117s 1s/step - loss: 0.8490 - auc: 0.8812 - val_loss: 0.2765 - val_auc: 0.7168\nEpoch 24/50\n117/117 [==============================] - 117s 1s/step - loss: 0.8396 - auc: 0.8833 - val_loss: 0.2939 - val_auc: 0.7357\nEpoch 25/50\n117/117 [==============================] - 117s 1s/step - loss: 0.8246 - auc: 0.8889 - val_loss: 0.3137 - val_auc: 0.7405\nEpoch 26/50\n117/117 [==============================] - 109s 935ms/step - loss: 0.8088 - auc: 0.8937 - val_loss: 0.3789 - val_auc: 0.7409\nEpoch 27/50\n117/117 [==============================] - 109s 935ms/step - loss: 0.8075 - auc: 0.8937 - val_loss: 0.2906 - val_auc: 0.7354\nEpoch 28/50\n117/117 [==============================] - 110s 941ms/step - loss: 0.7604 - auc: 0.9067 - val_loss: 0.2594 - val_auc: 0.7414\nEpoch 29/50\n117/117 [==============================] - 109s 933ms/step - loss: 0.7699 - auc: 0.9046 - val_loss: 0.2518 - val_auc: 0.7437\nEpoch 30/50\n117/117 [==============================] - 118s 1s/step - loss: 0.7395 - auc: 0.9115 - val_loss: 0.2536 - val_auc: 0.7457\nEpoch 31/50\n117/117 [==============================] - 109s 929ms/step - loss: 0.7723 - auc: 0.9039 - val_loss: 0.2483 - val_auc: 0.7449\nEpoch 32/50\n117/117 [==============================] - 118s 1s/step - loss: 0.7344 - auc: 0.9127 - val_loss: 0.3225 - val_auc: 0.7355\nEpoch 33/50\n117/117 [==============================] - 118s 1s/step - loss: 0.7386 - auc: 0.9113 - val_loss: 0.2721 - val_auc: 0.7430\nEpoch 34/50\n117/117 [==============================] - 110s 942ms/step - loss: 0.7358 - auc: 0.9134 - val_loss: 0.2921 - val_auc: 0.7412\nEpoch 35/50\n117/117 [==============================] - 118s 1s/step - loss: 0.7284 - auc: 0.9152 - val_loss: 0.2224 - val_auc: 0.7206\nEpoch 36/50\n117/117 [==============================] - 118s 1s/step - loss: 0.7551 - auc: 0.9076 - val_loss: 0.2501 - val_auc: 0.7317\nEpoch 37/50\n117/117 [==============================] - 118s 1s/step - loss: 0.6840 - auc: 0.9243 - val_loss: 0.2101 - val_auc: 0.7361\nEpoch 38/50\n117/117 [==============================] - 118s 1s/step - loss: 0.7065 - auc: 0.9187 - val_loss: 0.2241 - val_auc: 0.7376\nEpoch 39/50\n117/117 [==============================] - 110s 941ms/step - loss: 0.7083 - auc: 0.9185 - val_loss: 0.1937 - val_auc: 0.7253\nEpoch 40/50\n117/117 [==============================] - 117s 1s/step - loss: 0.7029 - auc: 0.9210 - val_loss: 0.2347 - val_auc: 0.7358\nEpoch 41/50\n117/117 [==============================] - 118s 1s/step - loss: 0.6949 - auc: 0.9227 - val_loss: 0.2324 - val_auc: 0.7405\nEpoch 42/50\n117/117 [==============================] - 110s 943ms/step - loss: 0.6674 - auc: 0.9263 - val_loss: 0.1988 - val_auc: 0.7498\nEpoch 43/50\n117/117 [==============================] - 109s 931ms/step - loss: 0.6751 - auc: 0.9277 - val_loss: 0.2069 - val_auc: 0.7507\nEpoch 44/50\n117/117 [==============================] - 117s 1s/step - loss: 0.6706 - auc: 0.9274 - val_loss: 0.1711 - val_auc: 0.7421\nEpoch 45/50\n117/117 [==============================] - 117s 999ms/step - loss: 0.6600 - auc: 0.9306 - val_loss: 0.1904 - val_auc: 0.7377\nEpoch 46/50\n117/117 [==============================] - 116s 995ms/step - loss: 0.6616 - auc: 0.9316 - val_loss: 0.2025 - val_auc: 0.7350\nEpoch 47/50\n117/117 [==============================] - 117s 1s/step - loss: 0.6728 - auc: 0.9280 - val_loss: 0.1786 - val_auc: 0.7334\nEpoch 48/50\n117/117 [==============================] - 118s 1s/step - loss: 0.6871 - auc: 0.9247 - val_loss: 0.2420 - val_auc: 0.7443\nEpoch 49/50\n117/117 [==============================] - 118s 1s/step - loss: 0.6747 - auc: 0.9284 - val_loss: 0.2082 - val_auc: 0.7380\nEpoch 50/50\n117/117 [==============================] - 109s 933ms/step - loss: 0.6455 - auc: 0.9334 - val_loss: 0.1415 - val_auc: 0.7418\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78821ddcb4f0>"},"metadata":{}}]},{"cell_type":"code","source":"model_book.evaluate(x = data.test['X'], y = data.test['y'])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T23:11:23.977302Z","iopub.execute_input":"2023-08-30T23:11:23.977778Z","iopub.status.idle":"2023-08-30T23:11:42.023705Z","shell.execute_reply.started":"2023-08-30T23:11:23.977741Z","shell.execute_reply":"2023-08-30T23:11:42.022726Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1079/1079 [==============================] - 18s 17ms/step - loss: 0.1376 - auc: 0.7446\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[0.13763456046581268, 0.7445834279060364]"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1D CNN model","metadata":{}},{"cell_type":"code","source":"model_cnn = tf.keras.models.Sequential([\n            tf.keras.layers.Conv1D(256, \n                                kernel_size = 3,\n                                padding = \"valid\", \n                                activation = \"relu\",\n                                input_shape=Input_Shape),    \n            tf.keras.layers.MaxPooling1D(3),\n            tf.keras.layers.Conv1D(256, \n                                kernel_size = 3,\n                                padding = \"valid\", \n                                activation = \"relu\"),    \n            tf.keras.layers.MaxPooling1D(3),\n            tf.keras.layers.Dropout(0.5),\n\n\n\n    \n            tf.keras.layers.Flatten(),\n#             tf.keras.layers.Dense(128, activation = 'relu'),\n#             tf.keras.layers.Dense(64, activation = 'relu'),\n#             tf.keras.layers.Dense(64),\n#             tf.keras.layers.Dropout(0.2),\n# #             tf.keras.layers.Dense(32),\n#             tf.keras.layers.Dense(16),\n            tf.keras.layers.Dense(1,activation='sigmoid') # ISPROBAJ OPET SA DOWNSAMPLING 50\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T11:20:23.015718Z","iopub.execute_input":"2023-08-30T11:20:23.016224Z","iopub.status.idle":"2023-08-30T11:20:23.107205Z","shell.execute_reply.started":"2023-08-30T11:20:23.016185Z","shell.execute_reply":"2023-08-30T11:20:23.106098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_cnn = tf.keras.optimizers.Adam(learning_rate = 1e-3)\nmodel_cnn.compile(optimizer = opt_cnn,\n                 loss = 'binary_crossentropy',\n                 metrics = METRICS)\nmodel_cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T11:20:24.976683Z","iopub.execute_input":"2023-08-30T11:20:24.977153Z","iopub.status.idle":"2023-08-30T11:20:25.017165Z","shell.execute_reply.started":"2023-08-30T11:20:24.977117Z","shell.execute_reply":"2023-08-30T11:20:25.015928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1234)\nmodel_cnn.fit(x = data.train['X'], y= data.train['y'], \n              validation_data = (data.valid['X'], data.valid['y']),\n              sample_weight = data.train['w'],\n             epochs = 10, batch_size = 512)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T11:20:27.720943Z","iopub.execute_input":"2023-08-30T11:20:27.721478Z","iopub.status.idle":"2023-08-30T11:54:07.509044Z","shell.execute_reply.started":"2023-08-30T11:20:27.721401Z","shell.execute_reply":"2023-08-30T11:54:07.507726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.evaluate(data.test['X'],data.test['y'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T11:54:10.515633Z","iopub.execute_input":"2023-08-30T11:54:10.516134Z","iopub.status.idle":"2023-08-30T11:54:21.020023Z","shell.execute_reply.started":"2023-08-30T11:54:10.516095Z","shell.execute_reply":"2023-08-30T11:54:21.018827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1D CNN + Bi-LSTM","metadata":{}},{"cell_type":"code","source":"model_cnn_bilstm = tf.keras.models.Sequential([\n    tf.keras.layers.Conv1D(256, \n                          kernel_size = 3, \n                          input_shape = Input_Shape),\n    tf.keras.layers.MaxPooling1D(3),\n#     tf.keras.layers.Conv1D(256, \n#                           kernel_size = 3),\n#     tf.keras.layers.MaxPooling1D(3),\n    tf.keras.layers.Dropout(0.25), \n    \n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n    tf.keras.layers.Dropout(0.25),\n    \n    tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(128),\n#     tf.keras.layers.Dense(64),\n#     tf.keras.layers.Dropout(0.2),\n#     tf.keras.layers.Dense(16),\n    tf.keras.layers.Dense(1, activation = 'sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T14:44:35.081263Z","iopub.execute_input":"2023-08-30T14:44:35.081839Z","iopub.status.idle":"2023-08-30T14:44:35.810053Z","shell.execute_reply.started":"2023-08-30T14:44:35.081791Z","shell.execute_reply":"2023-08-30T14:44:35.808563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn_bilstm.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n                        loss = 'binary_crossentropy',\n                        metrics = METRICS)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T14:44:37.958207Z","iopub.execute_input":"2023-08-30T14:44:37.958749Z","iopub.status.idle":"2023-08-30T14:44:37.975121Z","shell.execute_reply.started":"2023-08-30T14:44:37.958707Z","shell.execute_reply":"2023-08-30T14:44:37.973851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1234)\nmodel_cnn_bilstm.fit(x = data.train['X'], y = data.train['y'],\n                  validation_data = (data.valid['X'], data.valid['y']),\n                      sample_weight = data.train['w'],\n                                    epochs = 15, batch_size =512)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T14:45:37.537079Z","iopub.execute_input":"2023-08-30T14:45:37.537918Z","iopub.status.idle":"2023-08-30T16:18:19.056781Z","shell.execute_reply.started":"2023-08-30T14:45:37.537871Z","shell.execute_reply":"2023-08-30T16:18:19.055176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn_bilstm.evaluate(x = data.test['X'], y = data.test['y'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:19:44.303766Z","iopub.execute_input":"2023-08-30T16:19:44.304296Z","iopub.status.idle":"2023-08-30T16:20:25.339973Z","shell.execute_reply.started":"2023-08-30T16:19:44.304250Z","shell.execute_reply":"2023-08-30T16:20:25.338689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2023-08-28T06:52:52.172269Z","iopub.execute_input":"2023-08-28T06:52:52.172707Z","iopub.status.idle":"2023-08-28T06:52:52.178456Z","shell.execute_reply.started":"2023-08-28T06:52:52.172670Z","shell.execute_reply":"2023-08-28T06:52:52.176925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1234)\nkf = KFold(n_splits=5, random_state=42, shuffle=True)\n\nfold_no = 1       # counter for every K fold in cross validation proces\nauc_per_fold = [] # for capturing auc in every fold","metadata":{"execution":{"iopub.status.busy":"2023-08-28T06:52:55.245501Z","iopub.execute_input":"2023-08-28T06:52:55.246029Z","iopub.status.idle":"2023-08-28T06:52:55.253152Z","shell.execute_reply.started":"2023-08-28T06:52:55.245988Z","shell.execute_reply":"2023-08-28T06:52:55.251731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making a DataFrame from the train samples\n# for CrossValidation\nX = np.concatenate([data.train[\"X\"], data.test[\"X\"], data.valid[\"X\"]], axis = 0)\nY = np.concatenate([data.train[\"y\"], data.test[\"y\"], data.valid[\"y\"]], axis = 0)","metadata":{"execution":{"iopub.status.busy":"2023-08-28T06:52:57.918662Z","iopub.execute_input":"2023-08-28T06:52:57.919055Z","iopub.status.idle":"2023-08-28T06:52:57.997181Z","shell.execute_reply.started":"2023-08-28T06:52:57.919023Z","shell.execute_reply":"2023-08-28T06:52:57.995925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Input_Shape = X.shape[1:]","metadata":{"execution":{"iopub.status.busy":"2023-08-28T06:52:59.871703Z","iopub.execute_input":"2023-08-28T06:52:59.872098Z","iopub.status.idle":"2023-08-28T06:52:59.877357Z","shell.execute_reply.started":"2023-08-28T06:52:59.872069Z","shell.execute_reply":"2023-08-28T06:52:59.876009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV for book model","metadata":{}},{"cell_type":"code","source":"for train, test in kf.split(X,Y):\n    \n    # We have to define model in the loop, so we would have \n    model_book = tf.keras.models.Sequential([\n    tf.keras.layers.Conv1D(filters = 30, \n                           kernel_size = 10,\n                          activation = 'relu',\n                          padding = 'same',\n                          input_shape = Input_Shape),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Conv1D(filters = 30, \n                           kernel_size = 10,\n                          activation = 'relu',\n                          padding = 'same'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Conv1D(filters = 30, \n                           kernel_size = 10,\n                          activation = 'relu',\n                          padding = 'same'),\n        tf.keras.layers.Dropout(0.5),\n    \n        tf.keras.layers.Flatten(),\n#         tf.keras.layers.Dense(64, activation = 'relu'),\n        tf.keras.layers.Dense(1, activation = 'sigmoid')\n        ])\n    model_book.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n                        loss = 'binary_crossentropy',\n                        metrics = METRICS)\n    \n    history = model_book.fit(X[train], Y[train],\n                            epochs = 20, batch_size = BATCH_SIZE)\n    \n    scores = model_book.evaluate(X[test], Y[test],verbose = 0)\n    \n    auc_per_fold.append(scores[1])\n    \n    fold_no +=1","metadata":{"execution":{"iopub.status.busy":"2023-08-26T19:46:26.148117Z","iopub.execute_input":"2023-08-26T19:46:26.148562Z","iopub.status.idle":"2023-08-26T20:57:51.999069Z","shell.execute_reply.started":"2023-08-26T19:46:26.148528Z","shell.execute_reply":"2023-08-26T20:57:51.997874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_per_fold","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:02:49.471799Z","iopub.execute_input":"2023-08-26T21:02:49.472234Z","iopub.status.idle":"2023-08-26T21:02:49.479416Z","shell.execute_reply.started":"2023-08-26T21:02:49.472201Z","shell.execute_reply":"2023-08-26T21:02:49.478411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV for 1D CNN","metadata":{}},{"cell_type":"code","source":"for train, test in kf.split(X,Y):\n    \n    # We have to define model in the loop, so we would have \n    model_cnn = tf.keras.models.Sequential([\n            tf.keras.layers.Conv1D(256, \n                                kernel_size = 3,\n                                padding = \"valid\", \n                                activation = \"relu\",\n                                input_shape=Input_Shape),    \n            tf.keras.layers.MaxPooling1D(3),\n            tf.keras.layers.Conv1D(256, \n                                kernel_size = 3,\n                                padding = \"valid\", \n                                activation = \"relu\"),    \n            tf.keras.layers.MaxPooling1D(3),\n            tf.keras.layers.Dropout(0.25),\n\n\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(128, activation = 'relu'),\n            tf.keras.layers.Dense(64, activation = 'relu'),\n            tf.keras.layers.Dense(64),\n            tf.keras.layers.Dropout(0.2),\n#             tf.keras.layers.Dense(32),\n            tf.keras.layers.Dense(16),\n            tf.keras.layers.Dense(1,activation='sigmoid')\n            ])\n    \n    opt_cnn = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    model_cnn.compile(optimizer = opt_cnn,\n                 loss = 'binary_crossentropy',\n                 metrics = METRICS)\n    \n    history = model_cnn.fit(X[train], Y[train],\n                            epochs = 10, batch_size = 128)\n    \n    scores = model_cnn.evaluate(X[test], Y[test],verbose = 0)\n    \n    auc_per_fold.append(scores[1])\n    \n    fold_no +=1","metadata":{"execution":{"iopub.status.busy":"2023-08-27T13:26:43.286392Z","iopub.execute_input":"2023-08-27T13:26:43.286811Z","iopub.status.idle":"2023-08-27T16:00:06.837644Z","shell.execute_reply.started":"2023-08-27T13:26:43.286776Z","shell.execute_reply":"2023-08-27T16:00:06.836689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_per_fold","metadata":{"execution":{"iopub.status.busy":"2023-08-27T16:00:06.839751Z","iopub.execute_input":"2023-08-27T16:00:06.840138Z","iopub.status.idle":"2023-08-27T16:00:06.846904Z","shell.execute_reply.started":"2023-08-27T16:00:06.840101Z","shell.execute_reply":"2023-08-27T16:00:06.846082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1D CNN + BiLSTM","metadata":{}},{"cell_type":"code","source":"for train, test in kf.split(X,Y):\n    \n    # We have to define model in the loop, so we would have \n    model_cnn_bilstm = tf.keras.models.Sequential([\n    tf.keras.layers.Conv1D(256, \n                          kernel_size = 3, \n                          input_shape = Input_Shape),\n    tf.keras.layers.MaxPooling1D(3),\n    tf.keras.layers.Conv1D(256, \n                          kernel_size = 3),\n    tf.keras.layers.MaxPooling1D(3),\n    tf.keras.layers.Dropout(0.25),\n    \n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n    tf.keras.layers.Dropout(0.25),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128),\n    tf.keras.layers.Dense(64),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(16),\n    tf.keras.layers.Dense(1, activation = 'sigmoid')\n        ])\n    \n    opt_cnn = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    model_cnn_bilstm.compile(optimizer = opt_cnn,\n                 loss = 'binary_crossentropy',\n                 metrics = METRICS)\n    \n    history = model_cnn_bilstm.fit(X[train], Y[train],\n                            epochs = 15, batch_size = 128)\n    \n    scores = model_cnn_bilstm.evaluate(X[test], Y[test],verbose = 0)\n    \n    auc_per_fold.append(scores[1])\n    \n    fold_no +=1","metadata":{"execution":{"iopub.status.busy":"2023-08-28T06:53:08.826409Z","iopub.execute_input":"2023-08-28T06:53:08.826868Z","iopub.status.idle":"2023-08-28T12:48:39.195176Z","shell.execute_reply.started":"2023-08-28T06:53:08.826833Z","shell.execute_reply":"2023-08-28T12:48:39.194078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_per_fold","metadata":{"execution":{"iopub.status.busy":"2023-08-28T12:50:01.229127Z","iopub.execute_input":"2023-08-28T12:50:01.229729Z","iopub.status.idle":"2023-08-28T12:50:01.240159Z","shell.execute_reply.started":"2023-08-28T12:50:01.229684Z","shell.execute_reply":"2023-08-28T12:50:01.238673Z"},"trusted":true},"execution_count":null,"outputs":[]}]}